{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrsaDfdVHzxt"
      },
      "source": [
        "# Custom Training with YOLOv5\n",
        "\n",
        "We assemble a dataset and train a custom YOLOv5 model to recognize the objects in our dataset. To do so we will take the following steps:\n",
        "\n",
        "* Gather a dataset of images and label our dataset\n",
        "* Export our dataset to YOLOv5\n",
        "* Train YOLOv5 to recognize the objects in our dataset\n",
        "* Evaluate our YOLOv5 model's performance\n",
        "* Run test inference to view our model at work\n",
        "\n",
        "\n",
        "\n",
        "![](https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNveqeA1KXGy"
      },
      "source": [
        "# Step 1: Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTvDNSILZoN9",
        "outputId": "ab3b04c9-1014-4ff7-a332-d32aac6b9e6b"
      },
      "outputs": [],
      "source": [
        "#clone YOLOv5 and \n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP6USLgz2f0r"
      },
      "source": [
        "# Step 2: Assemble Our Dataset\n",
        "\n",
        "In order to train our custom model, we need to assemble a dataset of representative images with bounding box annotations around the objects that we want to detect. And we need our dataset to be in YOLOv5 format.\n",
        "\n",
        "In Roboflow, you can choose between two paths:\n",
        "\n",
        "* Convert an existing dataset to YOLOv5 format. Roboflow supports over [30 formats object detection formats](https://roboflow.com/formats) for conversion.\n",
        "* Upload raw images and annotate them in Roboflow with [Roboflow Annotate](https://docs.roboflow.com/annotate).\n",
        "\n",
        "# Annotate\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/roboflow-annotate.gif)\n",
        "\n",
        "# Version\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/robolfow-preprocessing.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIF6oKijdOK5"
      },
      "source": [
        "##Setting Up Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jjT5uIHo6l5"
      },
      "outputs": [],
      "source": [
        "# set up environment\n",
        "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZUIkNGEeKoD"
      },
      "source": [
        "##Cloning Dataset From Github Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqm87OjSdBAb",
        "outputId": "4b0c62b8-37b0-4003-f1ae-46b5eb1ea402"
      },
      "outputs": [],
      "source": [
        "\n",
        "# contains modified versions of detect.py, data.yaml\n",
        "# also contains best.pt !!!\n",
        "!git clone https://github.com/Ojus999/YOLOv5-ObjectDetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yJGIWwNedu-"
      },
      "outputs": [],
      "source": [
        "# setting path to the newly cloned repo\n",
        "PATH = \"/content/yolov5/YOLOv5-ObjectDetection\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3faeJluvedLx"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7yAi9hd-T4B"
      },
      "source": [
        "# Step 3: Train Our Custom YOLOv5 model\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
        "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaFNnxLJbq4J"
      },
      "outputs": [],
      "source": [
        "# img arg was 416\n",
        "# not required as best.pt is there in cloned repo\n",
        "# !python train.py --img 472 --batch 16 --epochs 50 --data {PATH}/data.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcIRLQOlA14A"
      },
      "source": [
        "# Evaluate Custom YOLOv5 Detector Performance\n",
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile.\n",
        "\n",
        "If you are new to these metrics, the one you want to focus on is `mAP_0.5` - learn more about mean average precision [here](https://blog.roboflow.com/mean-average-precision/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y09WUNlxXWko"
      },
      "outputs": [],
      "source": [
        "# killing to prevent hanging\n",
        "!kill 3396"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jS9_BxdBBHL"
      },
      "outputs": [],
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "# not possible  as we have not trained\n",
        "# %reload_ext tensorboard\n",
        "# %tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUDnIK5oUEaj"
      },
      "source": [
        "##Creating Folder for Cropped Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsF4RhfwUEED"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('/content/yolov5/Cropped_Imgs'):\n",
        "  !mkdir {'/content/yolov5/Cropped_Imgs'}\n",
        "\n",
        "if not os.path.exists('/content/yolov5/Cropped_Imgs/License'):\n",
        "  !mkdir {'/content/yolov5/Cropped_Imgs/License'}\n",
        "\n",
        "if not os.path.exists('/content/yolov5/Cropped_Imgs/Face'):\n",
        "  !mkdir {'/content/yolov5/Cropped_Imgs/Face'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46VnblMXUXzU"
      },
      "source": [
        "##Deleting Files in Cropped Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFactHWwUBda"
      },
      "outputs": [],
      "source": [
        "if os.path.exists('/content/yolov5/Cropped_Imgs/Face'):\n",
        "  Path = '/content/yolov5/Cropped_Imgs/Face'\n",
        "  for file in os.listdir(Path):\n",
        "    os.unlink(os.path.join(Path,file))\n",
        "\n",
        "if os.path.exists('/content/yolov5/Cropped_Imgs/License'):\n",
        "  Path = '/content/yolov5/Cropped_Imgs/License'\n",
        "  for file in os.listdir(Path):\n",
        "    os.unlink(os.path.join(Path,file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib7Ilv9a0e-_"
      },
      "source": [
        "##Move Modified Detect.py To The Required Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Q18B-_ah0k3b",
        "outputId": "ed7d169f-ad9d-41a8-bf4e-126c596a2f2e"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "\n",
        "src_path = \"/content/yolov5/YOLOv5-ObjectDetection/detect-1.py\"\n",
        "dst_path = \"/content/yolov5/detect-1.py\"\n",
        "shutil.move(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtmS7_TXFsT3"
      },
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWjjiBcic3Vz",
        "outputId": "988757f0-a93a-4848-accc-773bbf02b40d"
      },
      "outputs": [],
      "source": [
        "!python detect-1.py --weights {PATH}/best.pt --img 416 --conf 0.7 --source {PATH}/test/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtB05_Njyq3_"
      },
      "outputs": [],
      "source": [
        "#!python detect.py --weights runs/train/exp/weights/best.pt --img 416 --conf 0.7 --source {dataset.location}/test/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbUn4_b9GCKO"
      },
      "outputs": [],
      "source": [
        "#display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvzLqlQo2DkG"
      },
      "source": [
        "##Downloading The Cropped Images Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM_0zHZR3jpR"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('/content/Zip_Files'):\n",
        "  !mkdir {'/content/Zip_Files'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM2rNzye2DCp"
      },
      "outputs": [],
      "source": [
        "!zip -r \"/content/Zip_Files/Face.zip\" \"/content/yolov5/Cropped_Imgs/Face\"\n",
        "!zip -r \"/content/Zip_Files/License.zip\" \"/content/yolov5/Cropped_Imgs/License\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcSy4QjIZuoh"
      },
      "source": [
        "##Video\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFrV3nigZxx0"
      },
      "outputs": [],
      "source": [
        "# for displaying og video\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from skimage.transform import resize\n",
        "from IPython.display import HTML\n",
        "\n",
        "def display_video(video):\n",
        "    fig = plt.figure(figsize=(3,3))  #Display size specification\n",
        "\n",
        "    mov = []\n",
        "    for i in range(len(video)):  #Append videos one by one to mov\n",
        "        img = plt.imshow(video[i], animated=True)\n",
        "        plt.axis('off')\n",
        "        mov.append([img])\n",
        "\n",
        "    #Animation creation\n",
        "    anime = animation.ArtistAnimation(fig, mov, interval=50, repeat_delay=1000)\n",
        "\n",
        "    plt.close()\n",
        "    return anime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Btv308AqZzTS"
      },
      "outputs": [],
      "source": [
        "video = imageio.mimread('/content/yolov5/runs/detect/exp4/video2.mp4',memtest=False)  #Loading video\n",
        "#video = [resize(frame, (256, 256))[..., :3] for frame in video]    #Size adjustment (if necessary)\n",
        "HTML(display_video(video).to_html5_video())  #Inline video display in HTML5"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yNveqeA1KXGy"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
